{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91edf113-8196-4230-9caf-5e8d1dadaf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f54a66-fc19-4e1d-a5e7-ae38be373ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = '/Users/dakshbhatnagar/Spark'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb6366d-b4b3-4b71-9ee6-c0e0974ecc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f576c674-92c0-4c40-8338-42972138c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/30 17:17:02 WARN Utils: Your hostname, Dakshs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.107 instead (on interface en0)\n",
      "24/11/30 17:17:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/30 17:17:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark-Get-Started\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94236d6-6375-48d9-a386-e77c6afed504",
   "metadata": {},
   "source": [
    "## How to read in a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42bebc0-1f16-4926-afcb-095ab7547d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+-----------------------+------------+--------------------+-------+----+-------------+\n",
      "|               Name|Emp ID|Gender|Education Qualification|Date of Join|           Job Title| Salary| Age|Leave Balance|\n",
      "+-------------------+------+------+-----------------------+------------+--------------------+-------+----+-------------+\n",
      "|       Barr Faughny|AC0001|  Male|      Bachelor's Degree|   12-Jun-20|         Chocolatier|$51,300|26.0|           13|\n",
      "|Dennison Crosswaite|AC0002|Female|                Diploma|   18-Feb-21| Production Operator|$38,300|32.7|           12|\n",
      "|    Gunar Cockshoot|AC0003|  Male|    High School Diploma|   05-Sep-22| Packaging Associate|$31,400|34.3|           16|\n",
      "|     Wilone O'Kielt|AC0004|Female|      Bachelor's Degree|   20-Nov-19|Marketing Specialist|$60,700|29.6|           21|\n",
      "|       Gigi Bohling|AC0005|  Male|        Master's Degree|   08-Apr-18|  Research Scientist|$77,300|30.3|           23|\n",
      "+-------------------+------+------+-----------------------+------------+--------------------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_file = os.path.join(os.getcwd(), \"train.csv\")\n",
    "# Download the file to local storage\n",
    "if os.path.exists(local_file):\n",
    "    spark = SparkSession.builder.appName('density_forecasting').getOrCreate()\n",
    "    # Load the local file into PySpark\n",
    "    df = spark.read.csv(path=local_file, inferSchema=True, header=True)\n",
    "else:\n",
    "    url = 'https://raw.githubusercontent.com/dakshbhatnagar/Datasets/refs/heads/main/employee_data/HRdata.csv'\n",
    "    local_file = os.path.join(os.getcwd(), \"train.csv\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(local_file, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"File downloaded to {local_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. HTTP Status Code: {response.status_code}\")\n",
    "    \n",
    "    # Initialize Spark Session\n",
    "    spark = SparkSession.builder.appName('density_forecasting').getOrCreate()\n",
    "    \n",
    "    # Load the local file into PySpark\n",
    "    df = spark.read.csv(path=local_file, inferSchema=True, header=True)\n",
    "    \n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b8b358-1e71-476c-9f4f-ef26aa686231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+------+-----------------------+------------+--------------------+-------+------------------+-----------------+\n",
      "|summary|        Name|Emp ID|Gender|Education Qualification|Date of Join|           Job Title| Salary|               Age|    Leave Balance|\n",
      "+-------+------------+------+------+-----------------------+------------+--------------------+-------+------------------+-----------------+\n",
      "|  count|         161|   161|   161|                    161|         161|                 161|    161|               161|              161|\n",
      "|   mean|        NULL|  NULL|  NULL|                   NULL|        NULL|                NULL|   NULL|35.204968944099384|16.41614906832298|\n",
      "| stddev|        NULL|  NULL|  NULL|                   NULL|        NULL|                NULL|   NULL| 8.602309292002904|4.980661359462189|\n",
      "|    min|A R Rahadude|AC0001|Female|      Bachelor's Degree|   01-Jan-23|         Chocolatier|$28,900|              23.5|                2|\n",
      "|    max|  Zara Verma|AC0161|  Male|        Master's Degree|   31-Oct-21|Sales Representative|$85,000|              66.7|               37|\n",
      "+-------+------------+------+------+-----------------------+------------+--------------------+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5089a-5530-4c56-b51c-34636f83263c",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13dab15-0ed7-45ee-8a6a-056a73069cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('emp_id', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('education_qualification', 'string'),\n",
       " ('date_of_join', 'date'),\n",
       " ('job_title', 'string'),\n",
       " ('salary', 'int'),\n",
       " ('age', 'double'),\n",
       " ('leave_balance', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Removing unncessary characters in the column values and changing the datatype\n",
    "df = df.withColumn('Salary', f.translate(f.col('Salary'), \"$,\", \"\").cast(IntegerType()))\n",
    "\n",
    "#lowering the case of column name and removing any space\n",
    "df = df.toDF(*[col.lower().replace(\" \", \"_\") for col in df.columns])\n",
    "\n",
    "#Changing the date column from string to date\n",
    "df = df.withColumn('date_of_join', f.to_date(f.col('date_of_join'), 'dd-MMM-yy'))\n",
    "\n",
    "#checking the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2cbcf6-014d-4fe8-a2a1-914a3dcc8b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+-----------------------+------------+--------------------+------+----+-------------+\n",
      "|               name|emp_id|gender|education_qualification|date_of_join|           job_title|salary| age|leave_balance|\n",
      "+-------------------+------+------+-----------------------+------------+--------------------+------+----+-------------+\n",
      "|       Barr Faughny|AC0001|  Male|      Bachelor's Degree|  2020-06-12|         Chocolatier| 51300|26.0|           13|\n",
      "|Dennison Crosswaite|AC0002|Female|                Diploma|  2021-02-18| Production Operator| 38300|32.7|           12|\n",
      "|    Gunar Cockshoot|AC0003|  Male|    High School Diploma|  2022-09-05| Packaging Associate| 31400|34.3|           16|\n",
      "|     Wilone O'Kielt|AC0004|Female|      Bachelor's Degree|  2019-11-20|Marketing Specialist| 60700|29.6|           21|\n",
      "|       Gigi Bohling|AC0005|  Male|        Master's Degree|  2018-04-08|  Research Scientist| 77300|30.3|           23|\n",
      "+-------------------+------+------+-----------------------+------------+--------------------+------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the transformed dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e42654",
   "metadata": {},
   "source": [
    "## Answering Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37057c7-bde6-4c98-843c-4c15478bc2e5",
   "metadata": {},
   "source": [
    "### 1. How many people are in each job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049349a4-75ee-4a77-86e1-efc362e204de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           job_title|count|\n",
      "+--------------------+-----+\n",
      "| Packaging Associate|   22|\n",
      "| Production Operator|   20|\n",
      "|Sales Representative|   18|\n",
      "|     Quality Control|   17|\n",
      "|         Chocolatier|   17|\n",
      "|    Research Analyst|   16|\n",
      "|     Product Manager|   16|\n",
      "|  Research Scientist|   15|\n",
      "|   Marketing Manager|   10|\n",
      "|Marketing Specialist|   10|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df.groupBy('job_title')\\\n",
    "            .agg(f.count('job_title').alias('count'))\\\n",
    "            .orderBy('count', ascending=False)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4eb67-2651-4f34-9839-f26f85111e3e",
   "metadata": {},
   "source": [
    "### 2. Gender Break-down of the Staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c097e7-5ca9-48e4-b511-adf1d1a005cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|Female|   88|\n",
      "|  Male|   73|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gender = df.groupBy('gender')\\\n",
    "            .agg(f.count('gender').alias('count'))\\\n",
    "            .orderBy('count', ascending=False)\n",
    "gender.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0273ce-f51b-489f-82c8-9eb95d6717fb",
   "metadata": {},
   "source": [
    "### 3. Age Spread of the Staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e147cfcf-206e-4873-bedf-12fcce12f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|age_group|count|\n",
      "+---------+-----+\n",
      "|       20|    1|\n",
      "|       25|   24|\n",
      "|       30|   85|\n",
      "|       35|   32|\n",
      "|       40|    2|\n",
      "|       45|    3|\n",
      "|       50|    4|\n",
      "|       55|    1|\n",
      "|       60|    5|\n",
      "|       65|    4|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform the grouping and count\n",
    "group = (f.floor(df['age'] / 5) * 5).alias('age_group')  # Alias it directly here\n",
    "age_spread = df.groupBy(group).agg(f.count('*').alias('count')).orderBy(f.col('age_group'))\n",
    "\n",
    "age_spread.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876ff70-9b32-4c11-b436-972afb90652a",
   "metadata": {},
   "source": [
    "### 4. Which Jobs Pay More?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932c2101-ad6f-4c6f-a982-802b9672204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|           job_title|max_salary|\n",
      "+--------------------+----------+\n",
      "|     Product Manager|     85000|\n",
      "|  Research Scientist|     79300|\n",
      "|   Marketing Manager|     74900|\n",
      "|Marketing Specialist|     63600|\n",
      "|    Research Analyst|     60000|\n",
      "|         Chocolatier|     54900|\n",
      "|Sales Representative|     49800|\n",
      "|     Quality Control|     45000|\n",
      "| Production Operator|     39800|\n",
      "| Packaging Associate|     36200|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job_title').agg(f.max('salary').alias('max_salary')).orderBy(f.col('max_salary').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea85db-6033-4edf-b1a1-e6d03e38e793",
   "metadata": {},
   "source": [
    "### 5. Top Earners in Each Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25493865-becd-4fb8-8a47-a5d601b9323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------------+------+\n",
      "|            name|emp_id|           job_title|salary|\n",
      "+----------------+------+--------------------+------+\n",
      "|     Aarav Verma|AC0121|     Product Manager| 85000|\n",
      "|     Dell Molloy|AC0041|  Research Scientist| 79300|\n",
      "|   Krish Trivedi|AC0123|   Marketing Manager| 74900|\n",
      "| Merrilee Plenty|AC0056|Marketing Specialist| 63600|\n",
      "| Niall Selesnick|AC0027|    Research Analyst| 60000|\n",
      "|   Bernie Gorges|AC0090|         Chocolatier| 54900|\n",
      "|  Curtice Advani|AC0006|Sales Representative| 49800|\n",
      "|     Rhea Bhatia|AC0126|     Quality Control| 45000|\n",
      "|William Reeveley|AC0064| Production Operator| 39800|\n",
      "|     Shari McNee|AC0060| Packaging Associate| 36200|\n",
      "+----------------+------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Partitioning\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "window = Window.partitionBy('job_title').orderBy(f.col('salary').desc())\n",
    "max_sal_dept = df.withColumn('rank', f.row_number().over(window))\\\n",
    "  .filter(f.col('rank') == 1)\\\n",
    "  .select(['name', 'emp_id', 'job_title','salary'])\\\n",
    "  .orderBy(f.col('salary').desc())\n",
    "\n",
    "max_sal_dept.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9141034-d64f-4931-95fe-08924f37ec21",
   "metadata": {},
   "source": [
    "### 6. Qualification vs. Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe306c7-44b6-4862-be7c-9b9f8b4554ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------+\n",
      "|education_qualification|avg_salary|\n",
      "+-----------------------+----------+\n",
      "|        Master's Degree|  67037.93|\n",
      "|      Bachelor's Degree|  53881.63|\n",
      "|                Diploma|  51046.34|\n",
      "|    High School Diploma|  48904.76|\n",
      "+-----------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = df.groupBy('education_qualification').agg(f.round(f.mean('salary'),2).alias('avg_salary')).orderBy(f.col('avg_salary').desc())\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dced59-8f0e-43c3-90f5-baf58063f527",
   "metadata": {},
   "source": [
    "### 7. Staff Growth Trend Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc5887d4-7543-492c-a09e-2530cc13b03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+-------------+\n",
      "|date_of_join|emp|running_total|\n",
      "+------------+---+-------------+\n",
      "|  2017-04-11|  1|            1|\n",
      "|  2017-04-23|  1|            2|\n",
      "|  2017-05-11|  1|            3|\n",
      "|  2017-06-10|  1|            4|\n",
      "|  2017-06-14|  1|            5|\n",
      "|  2017-07-15|  1|            6|\n",
      "|  2017-07-23|  1|            7|\n",
      "|  2017-08-03|  1|            8|\n",
      "|  2017-10-31|  1|            9|\n",
      "|  2017-11-26|  1|           10|\n",
      "|  2018-04-06|  1|           11|\n",
      "|  2018-04-08|  1|           12|\n",
      "|  2018-05-03|  1|           13|\n",
      "|  2018-06-19|  1|           14|\n",
      "|  2018-07-27|  1|           15|\n",
      "|  2018-08-14|  1|           16|\n",
      "|  2018-09-04|  1|           17|\n",
      "|  2018-09-08|  1|           18|\n",
      "|  2018-09-09|  1|           19|\n",
      "|  2018-09-12|  1|           20|\n",
      "+------------+---+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = df.groupBy('date_of_join').agg(f.count('date_of_join').alias('emp'))\\\n",
    "            .orderBy(f.col('date_of_join').asc())\n",
    "\n",
    "window = Window.orderBy(f.col('date_of_join').asc())\n",
    "\n",
    "results = results.withColumn('running_total', f.sum('emp').over(window))\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cb8a2-0155-40ba-b325-f6fc87e1e10a",
   "metadata": {},
   "source": [
    "### 8. Leave Balance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31383d87-789d-4a49-a1be-4e4beb95f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+----------+\n",
      "|              name|leave_bal|avg_leaves|difference|\n",
      "+------------------+---------+----------+----------+\n",
      "|        Kiaan Shah|       39|      18.0|      21.0|\n",
      "|      Kiara Bhatia|       38|      18.0|      20.0|\n",
      "|        Avani Iyer|       38|      18.0|      20.0|\n",
      "|     Advait Kapoor|       37|      18.0|      19.0|\n",
      "|     Mollie Hanway|       35|      18.0|      17.0|\n",
      "|      Reyansh Rana|       34|      18.0|      16.0|\n",
      "|        Zara Verma|       33|      18.0|      15.0|\n",
      "|     Kabir Trivedi|       31|      18.0|      13.0|\n",
      "|         Dev Joshi|       31|      18.0|      13.0|\n",
      "|       Aanya Singh|       30|      18.0|      12.0|\n",
      "|     Allene Gobbet|       30|      18.0|      12.0|\n",
      "|        Pari Gupta|       29|      18.0|      11.0|\n",
      "|       Gray Seamon|       27|      18.0|       9.0|\n",
      "|      Jan Morforth|       25|      18.0|       7.0|\n",
      "|Valentia Etteridge|       25|      18.0|       7.0|\n",
      "|       Krish Rawat|       25|      18.0|       7.0|\n",
      "|       Kaine Padly|       24|      18.0|       6.0|\n",
      "|   Samaira Agarwal|       24|      18.0|       6.0|\n",
      "|      Kellsie Waby|       24|      18.0|       6.0|\n",
      "|     Aarush Mishra|       24|      18.0|       6.0|\n",
      "+------------------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping and aggregating data\n",
    "results = df.groupBy('name').agg(f.sum('leave_balance').alias('leave_bal')) \\\n",
    "            .orderBy(f.col('leave_bal').desc())\n",
    "\n",
    "# Define a window for calculating the average\n",
    "window = Window.orderBy(f.lit(1))  # Use a constant to calculate a global average\n",
    "\n",
    "# Add the 'avzg_leaves' column with the average leave balance\n",
    "results = results.withColumn('avg_leaves', f.round(f.mean('leave_bal').over(window),0))\n",
    "\n",
    "# Show the results\n",
    "results = results.withColumn('difference', f.col('leave_bal')-f.col('avg_leaves')).filter('difference > 0')\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc66898-d6a7-4ee9-8b3b-4391e6f69940",
   "metadata": {},
   "source": [
    "## Stop the session once done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b011c8-5b30-4043-ad5b-a36ffa7e3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de16ff-dcd6-49a4-af43-cfaa23b4a278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
